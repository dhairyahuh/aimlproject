{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fac374dd",
   "metadata": {},
   "source": [
    "> **Update:** Hyperparameter tuning now targets the real autism dataset. Run the helper cell below to populate `X_full`/`y_full` from the saved MFCC features before executing the experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e12984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "NOTEBOOK_DIR = Path().resolve()\n",
    "ASD_ROOT = NOTEBOOK_DIR.parent\n",
    "PROJECT_ROOT = ASD_ROOT.parent\n",
    "FEATURES_DIR = PROJECT_ROOT / \"features\"\n",
    "\n",
    "AUT_FILES = sorted(f for f in os.listdir(FEATURES_DIR) if f.startswith(\"aut_\"))\n",
    "NON_FILES = sorted(f for f in os.listdir(FEATURES_DIR) if f.startswith(\"split-\"))\n",
    "\n",
    "\n",
    "def load_features(file_list):\n",
    "    return np.vstack([\n",
    "        np.mean(np.load(FEATURES_DIR / name), axis=1)\n",
    "        for name in file_list\n",
    "    ])\n",
    "\n",
    "X_aut = load_features(AUT_FILES)\n",
    "X_non = load_features(NON_FILES)\n",
    "X_full = np.vstack([X_aut, X_non])\n",
    "y_full = np.hstack([np.ones(len(X_aut)), np.zeros(len(X_non))])\n",
    "\n",
    "print(\n",
    "    f\"Dataset ready for tuning: {len(X_full)} samples\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c7579",
   "metadata": {},
   "source": [
    "# Notebook 04: Hyperparameter Tuning\n",
    "## Systematic Grid Search and Random Search Exploration\n",
    "\n",
    "This notebook demonstrates **hyperparameter optimization** for the ASD/ADHD detection model.\n",
    "\n",
    "### Objectives\n",
    "- Explore learning rate, batch size, and architecture parameters\n",
    "- Conduct grid search and random search experiments\n",
    "- Compare results across parameter combinations\n",
    "- Identify optimal hyperparameters for final model\n",
    "- Visualize parameter impact on model performance\n",
    "\n",
    "### Hyperparameters Explored\n",
    "- Learning rate: [0.0001, 0.0005, 0.001, 0.005, 0.01]\n",
    "- Batch size: [16, 32, 64, 128]\n",
    "- Dropout rate: [0.1, 0.2, 0.3, 0.4]\n",
    "- Hidden layer units: [64, 128, 256, 512]\n",
    "- L2 regularization: [0.0001, 0.0005, 0.001, 0.005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53910bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "\n",
    "# Add paths\n",
    "project_root = Path('/').drive + '/AIML/ASD_ADHD_Detection'\n",
    "sys.path.insert(0, str(Path(project_root) / 'src'))\n",
    "\n",
    "print(\"✓ Environment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b616ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5d40f3",
   "metadata": {},
   "source": [
    "## Section 1: Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552ca029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_dir = Path('/').drive + '/AIML/data'\n",
    "\n",
    "X_train = np.load(data_dir + '/X_train.npy')\n",
    "X_val = np.load(data_dir + '/X_val.npy')\n",
    "X_test = np.load(data_dir + '/X_test.npy')\n",
    "y_train = np.load(data_dir + '/y_train.npy')\n",
    "y_val = np.load(data_dir + '/y_val.npy')\n",
    "y_test = np.load(data_dir + '/y_test.npy')\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_val_norm = scaler.transform(X_val)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(f\"Data shapes: X_train={X_train_norm.shape}, X_val={X_val_norm.shape}, X_test={X_test_norm.shape}\")\n",
    "print(f\"Input dim: {input_dim}, Classes: {n_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac804a83",
   "metadata": {},
   "source": [
    "## Section 2: Define Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6be970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid (limited for demonstration)\n",
    "param_grid = {\n",
    "    'learning_rate': [0.0005, 0.001, 0.005],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'dropout_rate': [0.2, 0.3],\n",
    "    'hidden_units': [128, 256],\n",
    "    'l2_reg': [0.0005, 0.001]\n",
    "}\n",
    "\n",
    "# Generate all combinations\n",
    "all_params = list(itertools.product(\n",
    "    param_grid['learning_rate'],\n",
    "    param_grid['batch_size'],\n",
    "    param_grid['dropout_rate'],\n",
    "    param_grid['hidden_units'],\n",
    "    param_grid['l2_reg']\n",
    "))\n",
    "\n",
    "print(f\"Total parameter combinations: {len(all_params)}\")\n",
    "print(f\"Sample combinations:\")\n",
    "for i, params in enumerate(all_params[:3]):\n",
    "    print(f\"  {i+1}. lr={params[0]}, bs={params[1]}, dr={params[2]}, hu={params[3]}, l2={params[4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae699c79",
   "metadata": {},
   "source": [
    "## Section 3: Build Function for Dynamic Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0de52ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_with_params(lr, dropout, hidden_units, l2_reg, input_dim, n_classes):\n",
    "    \"\"\"Build model with given hyperparameters.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(hidden_units, input_dim=input_dim, \n",
    "                    kernel_regularizer=keras.regularizers.l2(l2_reg)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(dropout),\n",
    "        \n",
    "        layers.Dense(hidden_units // 2, kernel_regularizer=keras.regularizers.l2(l2_reg)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(dropout),\n",
    "        \n",
    "        layers.Dense(n_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=lr),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "print(\"✓ Model builder function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1792841e",
   "metadata": {},
   "source": [
    "## Section 4: Grid Search - Train Multiple Configurations\n",
    "**Note:** This cell may take 5-10 minutes depending on your hardware. You can reduce combinations to speed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e18ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Store results\n",
    "grid_results = []\n",
    "\n",
    "print(f\"Grid Search: Training {len(all_params)} configurations...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for idx, params in enumerate(all_params, 1):\n",
    "    lr, batch_size, dropout, hidden_units, l2_reg = params\n",
    "    \n",
    "    # Build model\n",
    "    model = build_model_with_params(lr, dropout, hidden_units, l2_reg, input_dim, n_classes)\n",
    "    \n",
    "    # Train\n",
    "    early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=0)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train_norm, y_train,\n",
    "        validation_data=(X_val_norm, y_val),\n",
    "        epochs=30,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    _, val_acc = model.evaluate(X_val_norm, y_val, verbose=0)\n",
    "    _, test_acc = model.evaluate(X_test_norm, y_test, verbose=0)\n",
    "    \n",
    "    y_pred = model.predict(X_val_norm, verbose=0).argmax(axis=1)\n",
    "    val_f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "    \n",
    "    result = {\n",
    "        'config_id': idx,\n",
    "        'learning_rate': lr,\n",
    "        'batch_size': batch_size,\n",
    "        'dropout_rate': dropout,\n",
    "        'hidden_units': hidden_units,\n",
    "        'l2_reg': l2_reg,\n",
    "        'val_accuracy': float(val_acc),\n",
    "        'test_accuracy': float(test_acc),\n",
    "        'val_f1': float(val_f1),\n",
    "        'epochs_trained': len(history.history['loss'])\n",
    "    }\n",
    "    \n",
    "    grid_results.append(result)\n",
    "    \n",
    "    if idx % 5 == 0 or idx == 1:\n",
    "        print(f\"[{idx}/{len(all_params)}] lr={lr:.4f} bs={batch_size} dr={dropout} hu={hidden_units} | val_acc={val_acc:.4f} test_acc={test_acc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Grid Search Complete!\")\n",
    "\n",
    "# Create results dataframe\n",
    "df_grid = pd.DataFrame(grid_results)\n",
    "df_grid_sorted = df_grid.sort_values('val_accuracy', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 configurations (by validation accuracy):\")\n",
    "print(df_grid_sorted.head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2aabde",
   "metadata": {},
   "source": [
    "## Section 5: Analyze Parameter Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f9d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze impact of each parameter\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "# Learning Rate\n",
    "ax = axes[0, 0]\n",
    "lr_impact = df_grid.groupby('learning_rate')['val_accuracy'].agg(['mean', 'std'])\n",
    "ax.errorbar(lr_impact.index, lr_impact['mean'], yerr=lr_impact['std'], \n",
    "            marker='o', capsize=5, linewidth=2, markersize=8)\n",
    "ax.set_xlabel('Learning Rate', fontsize=11)\n",
    "ax.set_ylabel('Mean Validation Accuracy', fontsize=11)\n",
    "ax.set_title('Learning Rate Impact', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Batch Size\n",
    "ax = axes[0, 1]\n",
    "bs_impact = df_grid.groupby('batch_size')['val_accuracy'].agg(['mean', 'std'])\n",
    "ax.errorbar(bs_impact.index, bs_impact['mean'], yerr=bs_impact['std'], \n",
    "            marker='s', capsize=5, linewidth=2, markersize=8, color='orange')\n",
    "ax.set_xlabel('Batch Size', fontsize=11)\n",
    "ax.set_ylabel('Mean Validation Accuracy', fontsize=11)\n",
    "ax.set_title('Batch Size Impact', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Dropout Rate\n",
    "ax = axes[0, 2]\n",
    "dr_impact = df_grid.groupby('dropout_rate')['val_accuracy'].agg(['mean', 'std'])\n",
    "ax.errorbar(dr_impact.index, dr_impact['mean'], yerr=dr_impact['std'], \n",
    "            marker='^', capsize=5, linewidth=2, markersize=8, color='green')\n",
    "ax.set_xlabel('Dropout Rate', fontsize=11)\n",
    "ax.set_ylabel('Mean Validation Accuracy', fontsize=11)\n",
    "ax.set_title('Dropout Rate Impact', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hidden Units\n",
    "ax = axes[1, 0]\n",
    "hu_impact = df_grid.groupby('hidden_units')['val_accuracy'].agg(['mean', 'std'])\n",
    "ax.errorbar(hu_impact.index, hu_impact['mean'], yerr=hu_impact['std'], \n",
    "            marker='d', capsize=5, linewidth=2, markersize=8, color='red')\n",
    "ax.set_xlabel('Hidden Units', fontsize=11)\n",
    "ax.set_ylabel('Mean Validation Accuracy', fontsize=11)\n",
    "ax.set_title('Hidden Units Impact', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# L2 Regularization\n",
    "ax = axes[1, 1]\n",
    "l2_impact = df_grid.groupby('l2_reg')['val_accuracy'].agg(['mean', 'std'])\n",
    "ax.errorbar(l2_impact.index, l2_impact['mean'], yerr=l2_impact['std'], \n",
    "            marker='p', capsize=5, linewidth=2, markersize=8, color='purple')\n",
    "ax.set_xlabel('L2 Regularization', fontsize=11)\n",
    "ax.set_ylabel('Mean Validation Accuracy', fontsize=11)\n",
    "ax.set_title('L2 Regularization Impact', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Heatmap: Learning Rate vs Batch Size\n",
    "ax = axes[1, 2]\n",
    "pivot = df_grid.pivot_table(values='val_accuracy', index='learning_rate', columns='batch_size', aggfunc='mean')\n",
    "sns.heatmap(pivot, annot=True, fmt='.4f', cmap='RdYlGn', ax=ax, cbar_kws={'label': 'Val Accuracy'})\n",
    "ax.set_title('LR vs Batch Size', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Parameter impact analysis visualized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e66320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HYPERPARAMETER TUNING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nBest Configuration:\")\n",
    "best_config = df_grid_sorted.iloc[0]\n",
    "print(f\"  Val Accuracy: {best_config['val_accuracy']:.4f}\")\n",
    "print(f\"  Test Accuracy: {best_config['test_accuracy']:.4f}\")\n",
    "print(f\"  Learning Rate: {best_config['learning_rate']}\")\n",
    "print(f\"  Batch Size: {best_config['batch_size']}\")\n",
    "print(f\"  Dropout Rate: {best_config['dropout_rate']}\")\n",
    "print(f\"  Hidden Units: {best_config['hidden_units']}\")\n",
    "print(f\"  L2 Reg: {best_config['l2_reg']}\")\n",
    "\n",
    "print(\"\\nParameter Importance (by std dev):\")\n",
    "print(f\"  Learning Rate:     {df_grid.groupby('learning_rate')['val_accuracy'].std().mean():.6f}\")\n",
    "print(f\"  Batch Size:        {df_grid.groupby('batch_size')['val_accuracy'].std().mean():.6f}\")\n",
    "print(f\"  Dropout Rate:      {df_grid.groupby('dropout_rate')['val_accuracy'].std().mean():.6f}\")\n",
    "print(f\"  Hidden Units:      {df_grid.groupby('hidden_units')['val_accuracy'].std().mean():.6f}\")\n",
    "print(f\"  L2 Regularization: {df_grid.groupby('l2_reg')['val_accuracy'].std().mean():.6f}\")\n",
    "\n",
    "print(\"\\nAggregated Statistics:\")\n",
    "print(f\"  Mean Val Accuracy:  {df_grid['val_accuracy'].mean():.4f} ± {df_grid['val_accuracy'].std():.4f}\")\n",
    "print(f\"  Mean Test Accuracy: {df_grid['test_accuracy'].mean():.4f} ± {df_grid['test_accuracy'].std():.4f}\")\n",
    "print(f\"  Best Val Accuracy:  {df_grid['val_accuracy'].max():.4f}\")\n",
    "print(f\"  Worst Val Accuracy: {df_grid['val_accuracy'].min():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.13"
  },
  "kernelspec": {
   "name": "asd_adhd_detection",
   "display_name": "Python (ASD_ADHD_Detection)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}