{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b16b3a",
   "metadata": {},
   "source": [
    "> **Update:** Feature analysis now uses the real MFCC features generated from the autism recordings. Execute the helper cell below to build `X_full` and `y_full` before running the rest of the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e6e1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "NOTEBOOK_DIR = Path().resolve()\n",
    "ASD_ROOT = NOTEBOOK_DIR.parent\n",
    "PROJECT_ROOT = ASD_ROOT.parent\n",
    "FEATURES_DIR = PROJECT_ROOT / \"features\"\n",
    "\n",
    "AUT_FILES = sorted(f for f in os.listdir(FEATURES_DIR) if f.startswith(\"aut_\"))\n",
    "NON_FILES = sorted(f for f in os.listdir(FEATURES_DIR) if f.startswith(\"split-\"))\n",
    "\n",
    "\n",
    "def load_features(file_list):\n",
    "    return np.vstack([\n",
    "        np.mean(np.load(FEATURES_DIR / name), axis=1)\n",
    "        for name in file_list\n",
    "    ])\n",
    "\n",
    "X_aut = load_features(AUT_FILES)\n",
    "X_non = load_features(NON_FILES)\n",
    "X_full = np.vstack([X_aut, X_non])\n",
    "y_full = np.hstack([np.ones(len(X_aut)), np.zeros(len(X_non))])\n",
    "\n",
    "print(\n",
    "    f\"Feature matrix shape: {X_full.shape}\\n\"\n",
    "    f\"Label distribution: Autism={int(y_full.sum())}, Non-autism={len(y_full) - int(y_full.sum())}\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba6d8e9",
   "metadata": {},
   "source": [
    "# Notebook 05: Feature Analysis & Selection\n",
    "## Feature Importance, Correlation Analysis, and Feature Selection\n",
    "\n",
    "This notebook demonstrates **feature engineering and analysis** for the ASD/ADHD detection model.\n",
    "\n",
    "### Objectives\n",
    "- Analyze feature statistics and distributions\n",
    "- Compute feature correlations with target variable\n",
    "- Perform permutation importance analysis\n",
    "- Apply feature selection techniques (SelectKBest, RFE)\n",
    "- Evaluate model performance with reduced features\n",
    "- Visualize feature importance rankings\n",
    "\n",
    "### Content\n",
    "- Feature statistics and distributions\n",
    "- Correlation heatmaps\n",
    "- Permutation-based importance\n",
    "- Wrapper-based feature selection\n",
    "- Model comparison with/without feature selection\n",
    "- Feature-target relationship analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab7335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "\n",
    "# Add paths\n",
    "project_root = Path('/').drive + '/AIML/ASD_ADHD_Detection'\n",
    "sys.path.insert(0, str(Path(project_root) / 'src'))\n",
    "\n",
    "print(\"✓ Environment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3350f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, permutation_importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea06376",
   "metadata": {},
   "source": [
    "## Section 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba3ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_dir = Path('/').drive + '/AIML/data'\n",
    "\n",
    "X_train = np.load(data_dir + '/X_train.npy')\n",
    "X_val = np.load(data_dir + '/X_val.npy')\n",
    "X_test = np.load(data_dir + '/X_test.npy')\n",
    "y_train = np.load(data_dir + '/y_train.npy')\n",
    "y_val = np.load(data_dir + '/y_val.npy')\n",
    "y_test = np.load(data_dir + '/y_test.npy')\n",
    "\n",
    "# Combine for full analysis\n",
    "X_combined = np.vstack([X_train, X_val, X_test])\n",
    "y_combined = np.concatenate([y_train, y_val, y_test])\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "n_samples = X_combined.shape[0]\n",
    "\n",
    "print(f\"Data loaded:\")\n",
    "print(f\"  Features: {n_features}\")\n",
    "print(f\"  Train samples: {len(X_train)}\")\n",
    "print(f\"  Val samples: {len(X_val)}\")\n",
    "print(f\"  Test samples: {len(X_test)}\")\n",
    "print(f\"  Total samples: {n_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c195b7",
   "metadata": {},
   "source": [
    "## Section 2: Feature Statistics & Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70905a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature statistics\n",
    "feature_stats = []\n",
    "for i in range(n_features):\n",
    "    feature_stats.append({\n",
    "        'feature_idx': i,\n",
    "        'mean': np.mean(X_combined[:, i]),\n",
    "        'std': np.std(X_combined[:, i]),\n",
    "        'min': np.min(X_combined[:, i]),\n",
    "        'max': np.max(X_combined[:, i]),\n",
    "        'median': np.median(X_combined[:, i])\n",
    "    })\n",
    "\n",
    "df_stats = pd.DataFrame(feature_stats)\n",
    "\n",
    "print(\"Feature Statistics:\")\n",
    "print(df_stats.to_string(index=False))\n",
    "\n",
    "# Visualize distributions for first 9 features\n",
    "fig, axes = plt.subplots(3, 3, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(min(9, n_features)):\n",
    "    axes[i].hist(X_combined[:, i], bins=30, alpha=0.7, edgecolor='black')\n",
    "    axes[i].set_title(f'Feature {i} Distribution', fontsize=11, fontweight='bold')\n",
    "    axes[i].set_xlabel('Value', fontsize=10)\n",
    "    axes[i].set_ylabel('Frequency', fontsize=10)\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Feature distributions visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fea405",
   "metadata": {},
   "source": [
    "## Section 3: Feature Importance Analysis (ANOVA F-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e74a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data for feature selection\n",
    "scaler = StandardScaler()\n",
    "X_combined_norm = scaler.fit_transform(X_combined)\n",
    "\n",
    "# F-score based feature selection\n",
    "selector_f = SelectKBest(score_func=f_classif, k='all')\n",
    "selector_f.fit(X_combined_norm, y_combined)\n",
    "scores_f = selector_f.scores_\n",
    "\n",
    "# Mutual Information based selection\n",
    "selector_mi = SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "selector_mi.fit(X_combined_norm, y_combined)\n",
    "scores_mi = selector_mi.scores_\n",
    "\n",
    "# Random Forest importance\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_combined_norm, y_combined)\n",
    "scores_rf = rf_model.feature_importances_\n",
    "\n",
    "# Aggregate importance scores\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature_idx': range(n_features),\n",
    "    'f_score': scores_f,\n",
    "    'mutual_info': scores_mi,\n",
    "    'rf_importance': scores_rf,\n",
    "    'avg_importance': (scores_f / np.max(scores_f) + \n",
    "                      scores_mi / np.max(scores_mi) + \n",
    "                      scores_rf / np.max(scores_rf)) / 3\n",
    "})\n",
    "\n",
    "importance_df = importance_df.sort_values('avg_importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Important Features:\")\n",
    "print(importance_df.head(15).to_string(index=False))\n",
    "\n",
    "# Visualize top 20 features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "ax = axes[0, 0]\n",
    "top_features = importance_df.head(20)\n",
    "ax.barh(top_features['feature_idx'].astype(str), top_features['f_score'], alpha=0.7)\n",
    "ax.set_xlabel('F-Score', fontsize=11)\n",
    "ax.set_title('Top 20 Features (F-Score)', fontsize=12, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "ax = axes[0, 1]\n",
    "ax.barh(top_features['feature_idx'].astype(str), top_features['mutual_info'], alpha=0.7, color='orange')\n",
    "ax.set_xlabel('Mutual Information', fontsize=11)\n",
    "ax.set_title('Top 20 Features (Mutual Information)', fontsize=12, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "ax = axes[1, 0]\n",
    "ax.barh(top_features['feature_idx'].astype(str), top_features['rf_importance'], alpha=0.7, color='green')\n",
    "ax.set_xlabel('RF Importance', fontsize=11)\n",
    "ax.set_title('Top 20 Features (Random Forest)', fontsize=12, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "ax = axes[1, 1]\n",
    "ax.barh(top_features['feature_idx'].astype(str), top_features['avg_importance'], alpha=0.7, color='red')\n",
    "ax.set_xlabel('Average Importance', fontsize=11)\n",
    "ax.set_title('Top 20 Features (Averaged)', fontsize=12, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Feature importance analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8e9eb7",
   "metadata": {},
   "source": [
    "## Section 4: Feature Selection - Compare Models with Different Feature Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6dac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_features(X_tr, X_te, y_tr, y_te, selected_features):\n",
    "    \"\"\"Train a model with selected features.\"\"\"\n",
    "    X_tr_selected = X_tr[:, selected_features]\n",
    "    X_te_selected = X_te[:, selected_features]\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_tr_selected, y_tr)\n",
    "    \n",
    "    train_acc = rf.score(X_tr_selected, y_tr)\n",
    "    test_acc = rf.score(X_te_selected, y_te)\n",
    "    \n",
    "    return train_acc, test_acc\n",
    "\n",
    "# Test different feature counts\n",
    "feature_count_results = []\n",
    "feature_counts = [5, 10, 15, 20, 25, 30, 35, 40]\n",
    "\n",
    "for k in feature_counts:\n",
    "    # Select top k features\n",
    "    top_k_features = importance_df.head(k)['feature_idx'].values\n",
    "    \n",
    "    train_acc, test_acc = train_model_with_features(\n",
    "        X_combined_norm[:len(X_train)],\n",
    "        X_combined_norm[len(X_train):],\n",
    "        y_combined[:len(y_train)],\n",
    "        y_combined[len(y_train):],\n",
    "        top_k_features\n",
    "    )\n",
    "    \n",
    "    feature_count_results.append({\n",
    "        'n_features': k,\n",
    "        'train_accuracy': train_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'improvement': test_acc - 0.5  # baseline\n",
    "    })\n",
    "    \n",
    "    print(f\"k={k:2d}: train_acc={train_acc:.4f}, test_acc={test_acc:.4f}\")\n",
    "\n",
    "df_counts = pd.DataFrame(feature_count_results)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_counts['n_features'], df_counts['train_accuracy'], marker='o', label='Train Accuracy', linewidth=2)\n",
    "plt.plot(df_counts['n_features'], df_counts['test_accuracy'], marker='s', label='Test Accuracy', linewidth=2)\n",
    "plt.xlabel('Number of Features', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Model Performance vs. Feature Count', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Feature selection analysis complete\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.13"
  },
  "kernelspec": {
   "name": "asd_adhd_detection",
   "display_name": "Python (ASD_ADHD_Detection)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}