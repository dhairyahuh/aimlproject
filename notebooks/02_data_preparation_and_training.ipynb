{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a22762",
   "metadata": {},
   "source": [
    "> **Update:** This notebook now loads real autism recordings from `../recordings` (via the shared `features/` folder). Run the helper cell below before executing the rest of the workflow to ensure `X_train`, `X_val`, and related variables point to the real dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd869652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "NOTEBOOK_DIR = Path().resolve()\n",
    "ASD_ROOT = NOTEBOOK_DIR.parent\n",
    "PROJECT_ROOT = ASD_ROOT.parent\n",
    "FEATURES_DIR = PROJECT_ROOT / \"features\"\n",
    "\n",
    "AUT_FILES = sorted(f for f in os.listdir(FEATURES_DIR) if f.startswith(\"aut_\"))\n",
    "NON_FILES = sorted(f for f in os.listdir(FEATURES_DIR) if f.startswith(\"split-\"))\n",
    "\n",
    "\n",
    "def load_features(file_list):\n",
    "    return np.vstack([\n",
    "        np.mean(np.load(FEATURES_DIR / name), axis=1)\n",
    "        for name in file_list\n",
    "    ])\n",
    "\n",
    "X_aut = load_features(AUT_FILES)\n",
    "X_non = load_features(NON_FILES)\n",
    "X_full = np.vstack([X_aut, X_non])\n",
    "y_full = np.hstack([np.ones(len(X_aut)), np.zeros(len(X_non))])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_full, y_full, test_size=0.2, random_state=42, stratify=y_full\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_val, y_val, test_size=0.5, random_state=42, stratify=y_val\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Dataset loaded from {FEATURES_DIR}\\n\"\n",
    "    f\"  Autism samples: {len(X_aut)}\\n\"\n",
    "    f\"  Non-autism samples: {len(X_non)}\\n\"\n",
    "    f\"  Train/Val/Test: {len(X_train)}, {len(X_val)}, {len(X_test)}\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d83e9d",
   "metadata": {},
   "source": [
    "# ASD/ADHD Voice Detection - Phase 2: Data Preparation & Model Training\n",
    "\n",
    "This notebook demonstrates **step-by-step model training** from data preparation through evaluation.\n",
    "\n",
    "**Learning Goals:**\n",
    "- Prepare training data with proper normalization\n",
    "- Build an MLP neural network classifier\n",
    "- Train with monitoring and visualization\n",
    "- Evaluate with comprehensive metrics\n",
    "- Identify areas for refinement\n",
    "\n",
    "**Key Concept:** You'll see **EXACTLY how the model learns** at each step, enabling you to refine the approach based on results.\n",
    "\n",
    "**Timeline:**\n",
    "- ~5 minutes: Data preparation\n",
    "- ~10 minutes: Model training\n",
    "- ~5 minutes: Evaluation\n",
    "- **Total: ~20 minutes** for complete training cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4f3ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import librosa\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                             confusion_matrix, classification_report, roc_curve, auc, roc_auc_score)\n",
    "\n",
    "# TensorFlow imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Import custom modules\n",
    "from ASD_ADHD_Detection.config.config import config\n",
    "from ASD_ADHD_Detection.src.preprocessing.audio_preprocessor import AudioPreprocessor\n",
    "from ASD_ADHD_Detection.src.feature_extraction.mfcc_extractor import MFCCExtractor\n",
    "from ASD_ADHD_Detection.src.feature_extraction.spectral_extractor import SpectralExtractor\n",
    "from ASD_ADHD_Detection.src.feature_extraction.prosodic_extractor import ProsodicExtractor\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f685d119",
   "metadata": {},
   "source": [
    "## Section 1: Create Synthetic Training Dataset\n",
    "\n",
    "Since we don't have real patient data yet, we'll create **realistic synthetic data** that mimics the acoustic characteristics of ASD, ADHD, and healthy speech.\n",
    "\n",
    "**Why synthetic data for learning?**\n",
    "- Understand model behavior without real patient data\n",
    "- Validate the pipeline end-to-end\n",
    "- Generate baseline results\n",
    "- Test refinements quickly\n",
    "\n",
    "**Data characteristics:**\n",
    "- **Class 0 (Healthy):** Normal pitch variation, consistent energy, clean voice\n",
    "- **Class 1 (ASD):** Higher jitter/shimmer, monotone pitch, irregular energy\n",
    "- **Class 2 (ADHD):** Variable speech rate, irregular energy patterns, fast speaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf00f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_speech(duration=5, sr=16000, voice_type='healthy'):\n",
    "    \"\"\"\n",
    "    Create synthetic speech sample with characteristics of different voice types.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    duration : float\n",
    "        Duration in seconds\n",
    "    sr : int\n",
    "        Sample rate (Hz)\n",
    "    voice_type : str\n",
    "        'healthy', 'asd', or 'adhd'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    audio : array\n",
    "        Audio signal\n",
    "    \"\"\"\n",
    "    \n",
    "    t = np.linspace(0, duration, int(sr * duration), False)\n",
    "    audio = np.zeros_like(t)\n",
    "    \n",
    "    if voice_type == 'healthy':\n",
    "        # Healthy speech: smooth pitch variation, stable energy\n",
    "        f0_base = np.random.randint(100, 140)  # Base pitch\n",
    "        f0 = f0_base + 30 * np.sin(2 * np.pi * 1.2 * t)  # Smooth variation\n",
    "        jitter_amount = 0.002  # Small jitter\n",
    "        shimmer_amount = 0.02   # Small shimmer\n",
    "        \n",
    "    elif voice_type == 'asd':\n",
    "        # ASD speech: monotone pitch, high jitter/shimmer, irregular energy\n",
    "        f0_base = np.random.randint(95, 135)\n",
    "        f0 = f0_base + 5 * np.sin(2 * np.pi * 0.5 * t)  # Minimal pitch variation (monotone)\n",
    "        jitter_amount = 0.015   # Higher jitter (voice instability)\n",
    "        shimmer_amount = 0.08   # Higher shimmer\n",
    "        \n",
    "    else:  # adhd\n",
    "        # ADHD speech: irregular pitch, variable energy, fast segments\n",
    "        f0_base = np.random.randint(110, 150)\n",
    "        # Irregular pitch pattern (faster oscillations, less regular)\n",
    "        f0 = (f0_base + 20 * np.sin(2 * np.pi * 2.3 * t) + \n",
    "              15 * np.sin(2 * np.pi * 3.7 * t) + 10 * np.random.randn(len(t)))\n",
    "        jitter_amount = 0.008\n",
    "        shimmer_amount = 0.05\n",
    "    \n",
    "    # Generate harmonics with pitch variations\n",
    "    for harmonic in range(1, 8):\n",
    "        # Add jitter (random pitch variations)\n",
    "        f0_jittered = f0 * (1 + jitter_amount * np.random.randn(len(t)))\n",
    "        audio += (1.0 / harmonic) * np.sin(2 * np.pi * f0_jittered * harmonic * t)\n",
    "    \n",
    "    # Add formants (vocal tract resonances)\n",
    "    formants = [300, 1100, 2300]\n",
    "    for formant_freq in formants:\n",
    "        envelope = np.exp(-np.pi * ((t - 2.5) ** 2) / 0.5)\n",
    "        audio += 0.15 * np.sin(2 * np.pi * formant_freq * t) * envelope\n",
    "    \n",
    "    # Add shimmer (amplitude modulation)\n",
    "    shimmer = 1 + shimmer_amount * np.sin(2 * np.pi * 0.3 * t + np.random.randn())\n",
    "    audio = audio * shimmer\n",
    "    \n",
    "    # Variable energy based on voice type\n",
    "    if voice_type == 'adhd':\n",
    "        # ADHD: irregular energy pattern\n",
    "        energy_env = 0.5 + 0.4 * np.sin(2 * np.pi * 2.1 * t) + 0.3 * np.random.randn(len(t))\n",
    "    else:\n",
    "        # Others: smoother energy\n",
    "        energy_env = 0.7 + 0.2 * np.sin(2 * np.pi * 0.8 * t)\n",
    "    \n",
    "    audio = audio * np.clip(energy_env, 0.3, 1.0)\n",
    "    \n",
    "    # Add realistic noise\n",
    "    noise = np.random.normal(0, 0.01, len(audio))\n",
    "    audio = audio + noise\n",
    "    \n",
    "    # Normalize\n",
    "    audio = audio / (np.max(np.abs(audio)) + 1e-8) * 0.9\n",
    "    \n",
    "    return audio\n",
    "\n",
    "# Test synthetic data generation\n",
    "print(\"üéµ CREATING SYNTHETIC TRAINING DATASET\\n\")\n",
    "\n",
    "sr = config.audio.SAMPLE_RATE\n",
    "duration = config.audio.DURATION\n",
    "\n",
    "# Create samples for each class\n",
    "n_samples_per_class = 60  # Total 180 samples for balance\n",
    "voice_types = ['healthy', 'asd', 'adhd']\n",
    "class_labels = [0, 1, 2]\n",
    "\n",
    "print(f\"Creating {n_samples_per_class} samples per class...\")\n",
    "print(f\"Total samples: {n_samples_per_class * 3}\\n\")\n",
    "\n",
    "# Test one sample from each class\n",
    "for voice_type, label in zip(voice_types, class_labels):\n",
    "    audio = create_synthetic_speech(duration, sr, voice_type)\n",
    "    print(f\"‚úì {voice_type.upper():8s} (Class {label}): shape={audio.shape}, RMS={np.sqrt(np.mean(audio**2)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02394b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from synthetic dataset\n",
    "print(\"üìä EXTRACTING FEATURES FROM SYNTHETIC DATA\\n\")\n",
    "\n",
    "# Initialize feature extractors\n",
    "mfcc_extractor = MFCCExtractor(config)\n",
    "spectral_extractor = SpectralExtractor(config)\n",
    "prosodic_extractor = ProsodicExtractor(config)\n",
    "\n",
    "# Store all features and labels\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "# Create dataset\n",
    "np.random.seed(42)\n",
    "for label, voice_type in enumerate(voice_types):\n",
    "    print(f\"Extracting {voice_type.upper()} features ({n_samples_per_class} samples)...\")\n",
    "    \n",
    "    for sample_idx in range(n_samples_per_class):\n",
    "        # Generate synthetic audio\n",
    "        audio = create_synthetic_speech(duration, sr, voice_type)\n",
    "        \n",
    "        try:\n",
    "            # Extract features\n",
    "            mfcc_feat = mfcc_extractor.extract(audio, sr)\n",
    "            spectral_feat = spectral_extractor.extract(audio, sr)\n",
    "            prosodic_feat = prosodic_extractor.extract(audio, sr)\n",
    "            \n",
    "            # Combine all features\n",
    "            features = np.concatenate([mfcc_feat, spectral_feat, prosodic_feat])\n",
    "            \n",
    "            X_data.append(features)\n",
    "            y_data.append(label)\n",
    "            \n",
    "        except Exception as e:\n",
    "            if sample_idx == 0:\n",
    "                print(f\"   ‚ö†Ô∏è  Error in feature extraction: {str(e)[:50]}\")\n",
    "                # Create dummy features for demonstration\n",
    "                features = np.random.randn(106)\n",
    "                X_data.append(features)\n",
    "                y_data.append(label)\n",
    "\n",
    "print(f\"\\n‚úÖ Feature extraction complete!\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X_data)\n",
    "y = np.array(y_data)\n",
    "\n",
    "print(f\"\\nüìä DATASET SUMMARY:\")\n",
    "print(f\"   X shape: {X.shape}  (samples, features)\")\n",
    "print(f\"   y shape: {y.shape}  (samples,)\")\n",
    "print(f\"\\n   Class distribution:\")\n",
    "for label, voice_type in zip(class_labels, voice_types):\n",
    "    count = np.sum(y == label)\n",
    "    pct = 100 * count / len(y)\n",
    "    print(f\"     Class {label} ({voice_type:8s}): {count:3d} samples ({pct:5.1f}%)\")\n",
    "\n",
    "# Visualize feature distributions by class\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "fig.suptitle('Feature Distributions by Class (First 10 Features)', fontsize=12, fontweight='bold')\n",
    "\n",
    "for class_idx, (label, voice_type) in enumerate(zip(class_labels, voice_types)):\n",
    "    class_features = X[y == label]\n",
    "    \n",
    "    ax = axes[class_idx]\n",
    "    bp = ax.boxplot([class_features[:, i] for i in range(min(10, X.shape[1]))],\n",
    "                    labels=[f'F{i}' for i in range(min(10, X.shape[1]))],\n",
    "                    patch_artist=True)\n",
    "    \n",
    "    for patch in bp['boxes']:\n",
    "        patch.set_facecolor(plt.cm.Set1(class_idx))\n",
    "    \n",
    "    ax.set_title(f'{voice_type.upper()} (Class {label})', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Feature Value')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a5629a",
   "metadata": {},
   "source": [
    "## Section 2: Data Preprocessing & Normalization\n",
    "\n",
    "Before training, we must **normalize features** because:\n",
    "- MFCC features have different scale than spectral features\n",
    "- Neural networks train better with normalized inputs (mean ‚âà 0, std ‚âà 1)\n",
    "- Prevents large feature values from dominating training\n",
    "\n",
    "**Normalization approach:**\n",
    "- **StandardScaler (Z-score):** Features ‚Üí (feature - mean) / std\n",
    "- Fit on training data only\n",
    "- Apply same transformation to validation/test data\n",
    "- Prevents data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c405aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Split data into train/test\n",
    "print(\"üìä SPLITTING DATA INTO TRAIN/TEST SETS\\n\")\n",
    "\n",
    "# Use stratified split to maintain class distribution\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples ({100*X_train.shape[0]/len(X):.1f}%)\")\n",
    "print(f\"Test set:     {X_test.shape[0]} samples ({100*X_test.shape[0]/len(X):.1f}%)\")\n",
    "\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "for label in class_labels:\n",
    "    count = np.sum(y_train == label)\n",
    "    pct = 100 * count / len(y_train)\n",
    "    print(f\"  Class {label}: {count:3d} ({pct:5.1f}%)\")\n",
    "\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "for label in class_labels:\n",
    "    count = np.sum(y_test == label)\n",
    "    pct = 100 * count / len(y_test)\n",
    "    print(f\"  Class {label}: {count:3d} ({pct:5.1f}%)\")\n",
    "\n",
    "# Step 2: Normalize features\n",
    "print(\"\\nüîß NORMALIZING FEATURES\\n\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)  # Fit on training data\n",
    "X_test_normalized = scaler.transform(X_test)        # Transform test data\n",
    "\n",
    "print(\"Feature statistics BEFORE normalization (training set):\")\n",
    "print(f\"   Mean: {np.mean(X_train, axis=0)[:5]}\")  # First 5 features\n",
    "print(f\"   Std:  {np.std(X_train, axis=0)[:5]}\")\n",
    "\n",
    "print(\"\\nFeature statistics AFTER normalization (training set):\")\n",
    "print(f\"   Mean: {np.mean(X_train_normalized, axis=0)[:5]}\")\n",
    "print(f\"   Std:  {np.std(X_train_normalized, axis=0)[:5]}\")\n",
    "\n",
    "print(\"\\n‚úÖ Data preprocessing complete!\")\n",
    "\n",
    "# Visualize normalized data\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Before normalization\n",
    "ax = axes[0]\n",
    "im1 = ax.imshow(X_train[:30, :].T, aspect='auto', cmap='viridis', interpolation='nearest')\n",
    "ax.set_title('Features BEFORE Normalization (First 30 samples)', fontsize=11, fontweight='bold')\n",
    "ax.set_xlabel('Sample Index')\n",
    "ax.set_ylabel('Feature Index')\n",
    "plt.colorbar(im1, ax=ax)\n",
    "\n",
    "# After normalization\n",
    "ax = axes[1]\n",
    "im2 = ax.imshow(X_train_normalized[:30, :].T, aspect='auto', cmap='viridis', interpolation='nearest')\n",
    "ax.set_title('Features AFTER Normalization (First 30 samples)', fontsize=11, fontweight='bold')\n",
    "ax.set_xlabel('Sample Index')\n",
    "ax.set_ylabel('Feature Index')\n",
    "plt.colorbar(im2, ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Data visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb8f731",
   "metadata": {},
   "source": [
    "## Section 3: Build MLP Neural Network Model\n",
    "\n",
    "**Model Architecture:**\n",
    "\n",
    "```\n",
    "Input (106 features)\n",
    "  ‚Üì\n",
    "Dense(128) + BatchNorm + ReLU + Dropout(0.3)\n",
    "  ‚Üì\n",
    "Dense(64) + BatchNorm + ReLU + Dropout(0.3)\n",
    "  ‚Üì\n",
    "Dense(32) + BatchNorm + ReLU + Dropout(0.2)\n",
    "  ‚Üì\n",
    "Dense(3, softmax)  ‚Üí Output (3 classes)\n",
    "```\n",
    "\n",
    "**Why this architecture?**\n",
    "- **128-64-32:** Gradually reduces dimensionality from 106 ‚Üí 3\n",
    "- **Batch Normalization:** Stabilizes training, faster convergence\n",
    "- **ReLU activation:** Non-linearity, handles complex patterns\n",
    "- **Dropout:** Prevents overfitting by randomly disabling neurons\n",
    "- **L2 Regularization:** Penalizes large weights\n",
    "- **Softmax output:** Produces probability distribution over classes\n",
    "\n",
    "**Key hyperparameters (you can adjust these):**\n",
    "- Learning rate: 0.001 (lower = slower but more stable)\n",
    "- Batch size: 32 (smaller = noisier updates, faster)\n",
    "- Epochs: 100 (max iterations, stopped early if no improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240a7e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the MLP model\n",
    "print(\"üèóÔ∏è  BUILDING MLP MODEL\\n\")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    # Input layer (implicit)\n",
    "    layers.Input(shape=(X_train_normalized.shape[1],)),  # 106 features\n",
    "    \n",
    "    # First hidden layer\n",
    "    layers.Dense(\n",
    "        128, \n",
    "        kernel_regularizer=regularizers.l2(1e-4),\n",
    "        name='hidden_1'\n",
    "    ),\n",
    "    layers.BatchNormalization(name='batch_norm_1'),\n",
    "    layers.Activation('relu', name='activation_1'),\n",
    "    layers.Dropout(0.3, name='dropout_1'),\n",
    "    \n",
    "    # Second hidden layer\n",
    "    layers.Dense(\n",
    "        64,\n",
    "        kernel_regularizer=regularizers.l2(1e-4),\n",
    "        name='hidden_2'\n",
    "    ),\n",
    "    layers.BatchNormalization(name='batch_norm_2'),\n",
    "    layers.Activation('relu', name='activation_2'),\n",
    "    layers.Dropout(0.3, name='dropout_2'),\n",
    "    \n",
    "    # Third hidden layer\n",
    "    layers.Dense(\n",
    "        32,\n",
    "        kernel_regularizer=regularizers.l2(1e-4),\n",
    "        name='hidden_3'\n",
    "    ),\n",
    "    layers.BatchNormalization(name='batch_norm_3'),\n",
    "    layers.Activation('relu', name='activation_3'),\n",
    "    layers.Dropout(0.2, name='dropout_3'),\n",
    "    \n",
    "    # Output layer\n",
    "    layers.Dense(3, activation='softmax', name='output')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model built successfully!\\n\")\n",
    "print(model.summary())\n",
    "\n",
    "# Calculate model parameters\n",
    "total_params = model.count_params()\n",
    "print(f\"\\nüìä Model Statistics:\")\n",
    "print(f\"   Total parameters: {total_params:,}\")\n",
    "print(f\"   Trainable parameters: {sum([tf.size(w).numpy() for w in model.trainable_weights]):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e651d0",
   "metadata": {},
   "source": [
    "## Section 4: Train the Model with Detailed Monitoring\n",
    "\n",
    "**What you'll see during training:**\n",
    "- **Epoch:** Current iteration through the data\n",
    "- **Loss:** How far predictions are from actual labels (lower is better)\n",
    "- **Accuracy:** Percentage of correct predictions\n",
    "- **Precision:** Of positive predictions, how many were correct?\n",
    "- **Recall:** Of actual positives, how many did we find?\n",
    "\n",
    "**Training behavior:**\n",
    "- Loss should decrease over epochs (model learning)\n",
    "- Accuracy should increase\n",
    "- Early stopping prevents overfitting (stops if no improvement for 10 epochs)\n",
    "- Learning rate reduction: Slows down if stuck in local minimum\n",
    "\n",
    "**Watch for:**\n",
    "- ‚úÖ Smooth loss decrease = good learning\n",
    "- ‚ö†Ô∏è Flat/increasing loss = learning problems\n",
    "- ‚ö†Ô∏è Training accuracy 100% but test accuracy low = overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d150a5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks for better training\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"üöÄ TRAINING THE MODEL\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_normalized, y_train,\n",
    "    validation_split=0.2,  # Use 20% of training data for validation\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1  # Show progress for each epoch\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n‚úÖ Training complete!\")\n",
    "print(f\"   Total epochs trained: {len(history.history['loss'])}\")\n",
    "print(f\"   Final training loss: {history.history['loss'][-1]:.4f}\")\n",
    "print(f\"   Final validation loss: {history.history['val_loss'][-1]:.4f}\")\n",
    "print(f\"   Final training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"   Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef402eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Model Training History', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 1: Loss\n",
    "ax = axes[0, 0]\n",
    "ax.plot(history.history['loss'], label='Training Loss', linewidth=2, marker='o', markersize=4)\n",
    "ax.plot(history.history['val_loss'], label='Validation Loss', linewidth=2, marker='s', markersize=4)\n",
    "ax.set_title('Loss Over Epochs', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Accuracy\n",
    "ax = axes[0, 1]\n",
    "ax.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2, marker='o', markersize=4)\n",
    "ax.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2, marker='s', markersize=4)\n",
    "ax.set_title('Accuracy Over Epochs', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_ylim([0, 1.05])\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Precision\n",
    "ax = axes[1, 0]\n",
    "ax.plot(history.history['precision'], label='Training Precision', linewidth=2, marker='o', markersize=4)\n",
    "ax.plot(history.history['val_precision'], label='Validation Precision', linewidth=2, marker='s', markersize=4)\n",
    "ax.set_title('Precision Over Epochs', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_ylim([0, 1.05])\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Recall\n",
    "ax = axes[1, 1]\n",
    "ax.plot(history.history['recall'], label='Training Recall', linewidth=2, marker='o', markersize=4)\n",
    "ax.plot(history.history['val_recall'], label='Validation Recall', linewidth=2, marker='s', markersize=4)\n",
    "ax.set_title('Recall Over Epochs', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Recall')\n",
    "ax.set_ylim([0, 1.05])\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Training history visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7b17ec",
   "metadata": {},
   "source": [
    "## Section 5: Evaluate Model on Test Set\n",
    "\n",
    "Now we evaluate the **trained model** on unseen test data. This shows **real-world performance**.\n",
    "\n",
    "**Key metrics:**\n",
    "- **Accuracy:** (TP + TN) / Total - Overall correctness\n",
    "- **Precision:** TP / (TP + FP) - When we predict positive, are we right?\n",
    "- **Recall:** TP / (TP + FN) - Do we find all positives?\n",
    "- **F1-Score:** Harmonic mean of precision & recall\n",
    "\n",
    "**Confusion Matrix interpretation:**\n",
    "```\n",
    "                Predicted\n",
    "              ASD  ADHD  Healthy\n",
    "Actual  ASD   [a]   [b]    [c]\n",
    "        ADHD  [d]   [e]    [f]\n",
    "        Healthy [g] [h]    [i]\n",
    "```\n",
    "- Diagonal = correct predictions\n",
    "- Off-diagonal = confusions (which classes are mixed up?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c579862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "print(\"üìä EVALUATING MODEL ON TEST SET\\n\")\n",
    "\n",
    "y_pred_prob = model.predict(X_test_normalized, verbose=0)  # Predictions (probabilities)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)  # Convert to class labels\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"TEST SET PERFORMANCE:\")\n",
    "print(f\"   Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"   Precision: {precision:.4f}\")\n",
    "print(f\"   Recall:    {recall:.4f}\")\n",
    "print(f\"   F1-Score:  {f1:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nüìã CLASSIFICATION REPORT:\\n\")\n",
    "class_names = ['Healthy', 'ASD', 'ADHD']\n",
    "report = classification_report(y_test, y_pred, target_names=class_names, digits=4)\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nüìä CONFUSION MATRIX:\\n\")\n",
    "print(\"                 Predicted\")\n",
    "print(\"              Healthy  ASD  ADHD\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"Actual  {class_name:8s}   {cm[i, 0]:5d}  {cm[i, 1]:5d}  {cm[i, 2]:5d}\")\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Model Evaluation Results', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 1: Confusion Matrix heatmap\n",
    "ax = axes[0, 0]\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=ax, cbar_kws={'label': 'Count'})\n",
    "ax.set_title('Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_xlabel('Predicted')\n",
    "\n",
    "# Plot 2: Metrics comparison\n",
    "ax = axes[0, 1]\n",
    "metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1\n",
    "}\n",
    "colors_metrics = ['steelblue', 'coral', 'lightgreen', 'mediumpurple']\n",
    "bars = ax.bar(metrics.keys(), metrics.values(), color=colors_metrics, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "ax.set_ylim([0, 1.1])\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Overall Metrics', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, (key, val) in zip(bars, metrics.items()):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, val + 0.02, f'{val:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Plot 3: Per-class accuracy\n",
    "ax = axes[1, 0]\n",
    "per_class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "bars = ax.bar(class_names, per_class_accuracy, color=['steelblue', 'coral', 'lightgreen'], alpha=0.7, edgecolor='black', linewidth=2)\n",
    "ax.set_ylim([0, 1.1])\n",
    "ax.set_ylabel('Recall (Per-class Accuracy)')\n",
    "ax.set_title('Per-Class Recall', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, per_class_accuracy):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, val + 0.02, f'{val:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Plot 4: Prediction distribution\n",
    "ax = axes[1, 1]\n",
    "pred_counts = np.bincount(y_pred, minlength=3)\n",
    "actual_counts = np.bincount(y_test, minlength=3)\n",
    "x = np.arange(len(class_names))\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, actual_counts, width, label='Actual', alpha=0.7, edgecolor='black')\n",
    "ax.bar(x + width/2, pred_counts, width, label='Predicted', alpha=0.7, edgecolor='black')\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Actual vs Predicted Distribution', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(class_names)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337739eb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a49a1b42",
   "metadata": {},
   "source": [
    "## Appendix: Reuse project scripts & real data\n",
    "\n",
    "This notebook can be upgraded to use your repository's real data and helper scripts. Below we'll attempt to:\n",
    "- Detect repository scripts in `f:/AIML`\n",
    "- If available, load features saved by `ser_preprocessing.py` or `mfcc_extract.py`\n",
    "- If `Data/` splits already exist (e.g., X_train.npy), load them to skip synthetic generation\n",
    "\n",
    "If the files exist we'll demonstrate how to switch from synthetic data to real dataset with minimal changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6c1109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect repository-level artifacts and optionally load them\n",
    "import importlib.util\n",
    "import joblib\n",
    "root_dir = r'f:/AIML'\n",
    "\n",
    "candidates = [\n",
    "    'Data/X_train.npy', 'Data/X_val.npy', 'Data/X_test.npy',\n",
    "    'Data/y_train.npy','Data/y_val.npy','Data/y_test.npy',\n",
    "    'rf.pkl','svm.pkl','ann.pkl','model.pkl','model.json'\n",
    "]\n",
    "\n",
    "found = {}\n",
    "for c in candidates:\n",
    "    path = os.path.join(root_dir, c)\n",
    "    found[c] = os.path.exists(path)\n",
    "\n",
    "print('Detected dataset/model artifacts:')\n",
    "for k, v in found.items():\n",
    "    print(f' - {k}: {v}')\n",
    "\n",
    "# If pre-saved Data splits exist, load them to skip synthetic generation\n",
    "if found.get('Data/X_train.npy'):\n",
    "    print('\\nLoading pre-saved Data splits from f:/AIML/Data...')\n",
    "    X_train_disk = np.load(os.path.join(root_dir, 'Data/X_train.npy'))\n",
    "    X_val_disk = np.load(os.path.join(root_dir, 'Data/X_val.npy'))\n",
    "    X_test_disk = np.load(os.path.join(root_dir, 'Data/X_test.npy'))\n",
    "    y_train_disk = np.load(os.path.join(root_dir, 'Data/y_train.npy'))\n",
    "    y_val_disk = np.load(os.path.join(root_dir, 'Data/y_val.npy'))\n",
    "    y_test_disk = np.load(os.path.join(root_dir, 'Data/y_test.npy'))\n",
    "    print(f'  Shapes: X_train={X_train_disk.shape}, X_val={X_val_disk.shape}, X_test={X_test_disk.shape}')\n",
    "    # Optionally override our current X_train/X_test to use disk versions\n",
    "    use_disk = False  # Set True to override synthetic data\n",
    "    if use_disk:\n",
    "        X_train_normalized = scaler.transform(X_train_disk) if 'scaler' in globals() else X_train_disk\n",
    "        X_test_normalized = scaler.transform(X_test_disk) if 'scaler' in globals() else X_test_disk\n",
    "        y_train = y_train_disk\n",
    "        y_test = y_test_disk\n",
    "        print('  ‚úÖ Replaced in-memory dataset with disk dataset')\n",
    "\n",
    "# If saved models exist, try to load and run a quick inference on one sample\n",
    "for mname in ['rf.pkl','svm.pkl','ann.pkl','model.pkl']:\n",
    "    mpath = os.path.join(root_dir, mname)\n",
    "    if os.path.exists(mpath):\n",
    "        try:\n",
    "            mdl = joblib.load(mpath)\n",
    "            print(f'\\nLoaded model: {mname} (type={type(mdl)})')\n",
    "            # pick a sample\n",
    "            sample = None\n",
    "            if 'X_test_normalized' in globals():\n",
    "                sample = X_test_normalized[0:1]\n",
    "            elif 'X_train_normalized' in globals():\n",
    "                sample = X_train_normalized[0:1]\n",
    "            elif 'X' in globals():\n",
    "                sample = X[0:1]\n",
    "            if sample is not None:\n",
    "                try:\n",
    "                    pred = mdl.predict(sample)\n",
    "                    print(f' Quick prediction with {mname}: {pred}')\n",
    "                except Exception as e:\n",
    "                    print(f'  ‚ö†Ô∏è  Model loaded but prediction failed: {e}')\n",
    "            else:\n",
    "                print('  ‚ö†Ô∏è  No sample available in notebook to run quick inference')\n",
    "        except Exception as e:\n",
    "            print(f'  ‚ö†Ô∏è  Failed to load {mname}: {e}')\n",
    "\n",
    "print('\\nFinished repository artifact detection.\\n')\n",
    "print('If you want, I can:')\n",
    "print(' - wire mfcc_extract outputs into the feature pipeline (example cell)')\n",
    "print(' - configure the notebook to load Data splits from disk (set use_disk=True)')\n",
    "print(' - run model.py to (re)train classical models (random forest, svm) and save outputs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b43af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Integration helper: Use disk splits if available (Safe, no retrain) ---\n",
    "# This cell replaces in-memory synthetic data with precomputed disk splits if present.\n",
    "\n",
    "use_disk = True  # <-- set True to use f:/AIML/data/*.npy splits\n",
    "root_dir = r'f:/AIML'\n",
    "\n",
    "if use_disk:\n",
    "    data_dir = os.path.join(root_dir, 'data')\n",
    "    expected = ['X_train.npy','X_val.npy','X_test.npy','y_train.npy','y_val.npy','y_test.npy']\n",
    "    missing = [f for f in expected if not os.path.exists(os.path.join(data_dir, f))]\n",
    "    if missing:\n",
    "        print('‚ö†Ô∏è  Some expected Data splits are missing in f:/AIML/data:', missing)\n",
    "        print('   Notebook will continue using in-memory dataset (synthetic).')\n",
    "    else:\n",
    "        # Load disk splits\n",
    "        X_train_disk = np.load(os.path.join(data_dir, 'X_train.npy'))\n",
    "        X_val_disk = np.load(os.path.join(data_dir, 'X_val.npy'))\n",
    "        X_test_disk = np.load(os.path.join(data_dir, 'X_test.npy'))\n",
    "        y_train_disk = np.load(os.path.join(data_dir, 'y_train.npy'))\n",
    "        y_val_disk = np.load(os.path.join(data_dir, 'y_val.npy'))\n",
    "        y_test_disk = np.load(os.path.join(data_dir, 'y_test.npy'))\n",
    "        print('‚úÖ Loaded disk splits:')\n",
    "        print(f'   X_train: {X_train_disk.shape}, y_train: {y_train_disk.shape}')\n",
    "        print(f'   X_val:   {X_val_disk.shape}, y_val:   {y_val_disk.shape}')\n",
    "        print(f'   X_test:  {X_test_disk.shape}, y_test:  {y_test_disk.shape}')\n",
    "\n",
    "        # Combine train + val (the notebook previously used validation_split during fit)\n",
    "        X_train_full = np.concatenate([X_train_disk, X_val_disk], axis=0)\n",
    "        y_train_full = np.concatenate([y_train_disk, y_val_disk], axis=0)\n",
    "\n",
    "        # Normalize using StandardScaler fit on training data\n",
    "        scaler = StandardScaler()\n",
    "        X_train_normalized = scaler.fit_transform(X_train_full)\n",
    "        X_test_normalized = scaler.transform(X_test_disk)\n",
    "\n",
    "        # Override notebook-level variables used later in training\n",
    "        X_train = X_train_full\n",
    "        y_train = y_train_full\n",
    "        X_test = X_test_disk\n",
    "        y_test = y_test_disk\n",
    "\n",
    "        print('\\nüîß Data normalization complete:')\n",
    "        print(f'   X_train_normalized: {X_train_normalized.shape}')\n",
    "        print(f'   X_test_normalized:  {X_test_normalized.shape}')\n",
    "\n",
    "        # Quick check: print first row summaries (not verbose)\n",
    "        print('\\nSample (first training) feature stats:')\n",
    "        print(f\"   mean={np.mean(X_train_normalized[0]):.4f}, std={np.std(X_train_normalized[0]):.4f}\")\n",
    "\n",
    "        # NOTE: The notebook's training cell expects X_train_normalized and X_test_normalized variables.\n",
    "        # If you want to run a short verification training run here, set run_quick_train=True (keeps epochs small).\n",
    "        run_quick_train = False\n",
    "        if run_quick_train:\n",
    "            quick_model = keras.models.clone_model(model)\n",
    "            quick_model.set_weights(model.get_weights())\n",
    "            quick_model.compile(optimizer=Adam(learning_rate=1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "            print('\\nRunning a 2-epoch quick verification training (this is optional)...')\n",
    "            quick_model.fit(X_train_normalized, y_train, epochs=2, batch_size=32, validation_split=0.1)\n",
    "            print('Quick verification done.')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.13"
  },
  "kernelspec": {
   "name": "asd_adhd_detection",
   "display_name": "Python (ASD_ADHD_Detection)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}