{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f0cea5f",
   "metadata": {},
   "source": [
    "> **Update:** The cross-validation workflow below now draws from the real autism MFCC features stored in `../features`. Execute the helper cell that follows to build `X_full` and `y_full` from the recordings before running the rest of the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c063b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "NOTEBOOK_DIR = Path().resolve()\n",
    "ASD_ROOT = NOTEBOOK_DIR.parent\n",
    "PROJECT_ROOT = ASD_ROOT.parent\n",
    "FEATURES_DIR = PROJECT_ROOT / \"features\"\n",
    "\n",
    "AUT_FILES = sorted(f for f in os.listdir(FEATURES_DIR) if f.startswith(\"aut_\"))\n",
    "NON_FILES = sorted(f for f in os.listdir(FEATURES_DIR) if f.startswith(\"split-\"))\n",
    "\n",
    "\n",
    "def load_features(file_list):\n",
    "    return np.vstack([\n",
    "        np.mean(np.load(FEATURES_DIR / name), axis=1)\n",
    "        for name in file_list\n",
    "    ])\n",
    "\n",
    "X_aut = load_features(AUT_FILES)\n",
    "X_non = load_features(NON_FILES)\n",
    "X_full = np.vstack([X_aut, X_non])\n",
    "y_full = np.hstack([np.ones(len(X_aut)), np.zeros(len(X_non))])\n",
    "\n",
    "print(\n",
    "    f\"Loaded {len(X_full)} samples from {FEATURES_DIR}\\n\"\n",
    "    f\"  Autism: {len(X_aut)} | Non-autism: {len(X_non)}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2dc990",
   "metadata": {},
   "source": [
    "# Notebook 03: K-Fold Cross-Validation\n",
    "## Robust Model Evaluation with Multiple Folds\n",
    "\n",
    "This notebook demonstrates **K-Fold cross-validation** for the ASD/ADHD detection model.\n",
    "\n",
    "### Objectives\n",
    "- Split data into K folds for robust evaluation\n",
    "- Train independent models on each fold\n",
    "- Compute fold-specific and aggregated metrics\n",
    "- Calculate confidence intervals\n",
    "- Visualize per-fold performance\n",
    "- Generate comparative analysis across folds\n",
    "\n",
    "### What You'll Learn\n",
    "- How K-Fold improves model reliability\n",
    "- Per-fold performance interpretation\n",
    "- Aggregated metrics and confidence bounds\n",
    "- Statistical significance of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8049c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Add paths\n",
    "project_root = r'f:\\AIML\\ASD_ADHD_Detection'\n",
    "sys.path.insert(0, os.path.join(project_root, 'src'))\n",
    "\n",
    "print(\"Environment setup complete!\")\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97893ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    precision_recall_fscore_support, f1_score\n",
    ")\n",
    "\n",
    "print(\"✓ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8859ef",
   "metadata": {},
   "source": [
    "## Section 1: Load Data\n",
    "Load the precomputed data splits from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47792fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'f:\\AIML\\data'\n",
    "\n",
    "X_train = np.load(os.path.join(data_dir, 'X_train.npy'))\n",
    "X_val = np.load(os.path.join(data_dir, 'X_val.npy'))\n",
    "X_test = np.load(os.path.join(data_dir, 'X_test.npy'))\n",
    "y_train = np.load(os.path.join(data_dir, 'y_train.npy'))\n",
    "y_val = np.load(os.path.join(data_dir, 'y_val.npy'))\n",
    "y_test = np.load(os.path.join(data_dir, 'y_test.npy'))\n",
    "\n",
    "# Combine training and validation for K-Fold\n",
    "X_combined = np.vstack([X_train, X_val])\n",
    "y_combined = np.concatenate([y_train, y_val])\n",
    "\n",
    "print(f\"Combined training data shape: {X_combined.shape}\")\n",
    "print(f\"Combined labels shape: {y_combined.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_combined))}\")\n",
    "print(f\"\\nClass distribution (combined):\")\n",
    "for cls in np.unique(y_combined):\n",
    "    count = np.sum(y_combined == cls)\n",
    "    pct = 100 * count / len(y_combined)\n",
    "    print(f\"  Class {cls}: {count} samples ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e7a437",
   "metadata": {},
   "source": [
    "## Section 2: Setup K-Fold Cross-Validation\n",
    "Configure and initialize Stratified K-Fold for robust evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da136ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold configuration\n",
    "n_splits = 5\n",
    "random_state = 42\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "print(f\"K-Fold Configuration:\")\n",
    "print(f\"  Number of splits: {n_splits}\")\n",
    "print(f\"  Stratified: Yes (maintains class distribution)\")\n",
    "print(f\"  Random state: {random_state}\")\n",
    "print(f\"\\nFold details:\")\n",
    "\n",
    "fold_info = []\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_combined, y_combined)):\n",
    "    train_size = len(train_idx)\n",
    "    val_size = len(val_idx)\n",
    "    print(f\"  Fold {fold_idx + 1}: train={train_size}, val={val_size} (split={train_size/(train_size+val_size):.1%})\")\n",
    "    fold_info.append({'fold': fold_idx + 1, 'train_size': train_size, 'val_size': val_size})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a61a90e",
   "metadata": {},
   "source": [
    "## Section 3: Model Builder Function\n",
    "Define a function to create and train models for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c280cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim, n_classes):\n",
    "    \"\"\"Build a neural network model.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(256, input_dim=input_dim, kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        layers.Dense(128, kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        layers.Dense(64, kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        layers.Dense(n_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "print(\"✓ Model builder function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110eae1a",
   "metadata": {},
   "source": [
    "## Section 4: Train Models Across K Folds\n",
    "Train an independent model on each fold and evaluate on the held-out validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c65a514",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Storage for results\n",
    "fold_results = []\n",
    "fold_models = []\n",
    "fold_histories = []\n",
    "\n",
    "input_dim = X_combined.shape[1]\n",
    "n_classes = len(np.unique(y_combined))\n",
    "\n",
    "print(f\"Training {n_splits} models across K folds...\\n\")\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_combined, y_combined)):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"FOLD {fold_idx + 1}/{n_splits}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train_fold = X_combined[train_idx]\n",
    "    y_train_fold = y_combined[train_idx]\n",
    "    X_val_fold = X_combined[val_idx]\n",
    "    y_val_fold = y_combined[val_idx]\n",
    "    \n",
    "    # Normalize\n",
    "    scaler = StandardScaler()\n",
    "    X_train_fold_norm = scaler.fit_transform(X_train_fold)\n",
    "    X_val_fold_norm = scaler.transform(X_val_fold)\n",
    "    \n",
    "    # Build model\n",
    "    model = build_model(input_dim, n_classes)\n",
    "    \n",
    "    # Train\n",
    "    early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=0)\n",
    "    lr_schedule = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=0)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train_fold_norm, y_train_fold,\n",
    "        validation_data=(X_val_fold_norm, y_val_fold),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stop, lr_schedule],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    val_loss, val_acc = model.evaluate(X_val_fold_norm, y_val_fold, verbose=0)\n",
    "    y_pred = model.predict(X_val_fold_norm, verbose=0).argmax(axis=1)\n",
    "    \n",
    "    # Metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_val_fold, y_pred, average='weighted')\n",
    "    \n",
    "    result = {\n",
    "        'fold': fold_idx + 1,\n",
    "        'train_size': len(train_idx),\n",
    "        'val_size': len(val_idx),\n",
    "        'epochs_trained': len(history.history['loss']),\n",
    "        'val_accuracy': float(val_acc),\n",
    "        'val_loss': float(val_loss),\n",
    "        'val_precision': float(precision),\n",
    "        'val_recall': float(recall),\n",
    "        'val_f1': float(f1),\n",
    "    }\n",
    "    \n",
    "    fold_results.append(result)\n",
    "    fold_models.append(model)\n",
    "    fold_histories.append(history)\n",
    "    \n",
    "    print(f\"Epochs: {result['epochs_trained']} | Accuracy: {val_acc:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"K-Fold Training Complete!\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68078757",
   "metadata": {},
   "source": [
    "## Section 5: Fold Results Summary\n",
    "Display aggregated metrics across all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc51ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for easy viewing\n",
    "df_results = pd.DataFrame(fold_results)\n",
    "\n",
    "print(\"\\nPer-Fold Results:\")\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "# Aggregate metrics\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"AGGREGATED METRICS ACROSS K FOLDS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "metrics_to_agg = ['val_accuracy', 'val_precision', 'val_recall', 'val_f1']\n",
    "for metric in metrics_to_agg:\n",
    "    values = df_results[metric].values\n",
    "    mean = np.mean(values)\n",
    "    std = np.std(values)\n",
    "    ci_lower = mean - 1.96 * std / np.sqrt(len(values))\n",
    "    ci_upper = mean + 1.96 * std / np.sqrt(len(values))\n",
    "    print(f\"\\n{metric}:\")\n",
    "    print(f\"  Mean:              {mean:.4f}\")\n",
    "    print(f\"  Std Dev:           {std:.4f}\")\n",
    "    print(f\"  95% CI:            [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
    "    print(f\"  Per-fold values:   {[f'{v:.4f}' for v in values]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e75648c",
   "metadata": {},
   "source": [
    "## Section 6: Visualizations\n",
    "Create visualizations for per-fold performance and cross-fold comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89f6547",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot 1: Per-Fold Metrics Comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(len(fold_results))\n",
    "width = 0.2\n",
    "\n",
    "ax.bar(x - 1.5*width, df_results['val_accuracy'], width, label='Accuracy', alpha=0.8)\n",
    "ax.bar(x - 0.5*width, df_results['val_precision'], width, label='Precision', alpha=0.8)\n",
    "ax.bar(x + 0.5*width, df_results['val_recall'], width, label='Recall', alpha=0.8)\n",
    "ax.bar(x + 1.5*width, df_results['val_f1'], width, label='F1-Score', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Fold', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Per-Fold Performance Metrics', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'Fold {i+1}' for i in range(len(fold_results))])\n",
    "ax.legend(fontsize=11)\n",
    "ax.set_ylim([0, 1.0])\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Per-fold metrics visualization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e771f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Distribution with Error Bars\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "metrics = ['val_accuracy', 'val_precision', 'val_recall', 'val_f1']\n",
    "means = [df_results[m].mean() for m in metrics]\n",
    "stds = [df_results[m].std() for m in metrics]\n",
    "labels = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "\n",
    "x_pos = np.arange(len(labels))\n",
    "ax.bar(x_pos, means, yerr=stds, capsize=10, alpha=0.7, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Mean Metrics Across K-Folds (with Std Dev)', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(labels, fontsize=11)\n",
    "ax.set_ylim([0, 1.0])\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (mean, std) in enumerate(zip(means, stds)):\n",
    "    ax.text(i, mean + std + 0.02, f'{mean:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Aggregated metrics visualization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baa1171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: Training history for all folds\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for fold_idx, history in enumerate(fold_histories):\n",
    "    ax = axes[fold_idx]\n",
    "    ax.plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "    ax.plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "    ax.set_xlabel('Epoch', fontsize=11)\n",
    "    ax.set_ylabel('Accuracy', fontsize=11)\n",
    "    ax.set_title(f'Fold {fold_idx + 1} Training History', fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hide the extra subplot\n",
    "axes[5].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Training history visualizations complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9313ccb2",
   "metadata": {},
   "source": [
    "## Section 7: Best Model Evaluation on Test Set\n",
    "Use the best-performing fold model to evaluate on the held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c050a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best fold\n",
    "best_fold_idx = df_results['val_accuracy'].idxmax()\n",
    "best_fold_num = best_fold_idx + 1\n",
    "best_accuracy = df_results.loc[best_fold_idx, 'val_accuracy']\n",
    "\n",
    "print(f\"Best fold: Fold {best_fold_num} (accuracy: {best_accuracy:.4f})\")\n",
    "\n",
    "# Re-train best model on all combined training data for final test evaluation\n",
    "best_model_final = build_model(input_dim, n_classes)\n",
    "\n",
    "# Normalize combined data\n",
    "scaler_final = StandardScaler()\n",
    "X_combined_norm = scaler_final.fit_transform(X_combined)\n",
    "X_test_norm = scaler_final.transform(X_test)\n",
    "\n",
    "early_stop = callbacks.EarlyStopping(monitor='loss', patience=10, restore_best_weights=True, verbose=0)\n",
    "history_final = best_model_final.fit(\n",
    "    X_combined_norm, y_combined,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = best_model_final.evaluate(X_test_norm, y_test, verbose=0)\n",
    "y_pred_test = best_model_final.predict(X_test_norm, verbose=0).argmax(axis=1)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"TEST SET EVALUATION (Best Model Trained on All K-Fold Data)\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Test Loss:     {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print(\"\\nConfusion Matrix (Test):\")\n",
    "print(cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ea49ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test confusion matrix visualization\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
    "            xticklabels=range(n_classes), yticklabels=range(n_classes))\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('True', fontsize=12)\n",
    "plt.title('Confusion Matrix (Test Set - Best K-Fold Model)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.13"
  },
  "kernelspec": {
   "name": "asd_adhd_detection",
   "display_name": "Python (ASD_ADHD_Detection)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}