{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autism Audio Pipeline Snapshot\n",
    "\n",
    "This notebook captures the standalone scripts currently used for the autism audio pipeline (feature extraction, classical model training, and Streamlit UI). It mirrors the working production code so the project remains self-contained within `ASD_ADHD_Detection/`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MFCC Feature Extraction (`mfcc_extract.py`)\n",
    "\n",
    "This script scans the recordings directory, extracts 40 MFCC coefficients per frame, and saves each clip's feature matrix to the shared `features/` folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Configuration\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "ROOT_DIR = Path(__file__).resolve().parents[2]  # points to /Users/.../AIML\n",
    "RECORDINGS_DIR_CANDIDATES = [\n",
    "    ROOT_DIR / \"recordings\",  # legacy location\n",
    "    ROOT_DIR / \"ASD_ADHD_Detection\" / \"recordings\",  # current storage\n",
    "]\n",
    "FEATURES_DIR = ROOT_DIR / \"features\"\n",
    "SR = 22050\n",
    "N_MFCC = 40\n",
    "\n",
    "\n",
    "def extract_mfcc_features(audio_path: Path) -> np.ndarray:\n",
    "    \"\"\"Load audio file and compute MFCC feature matrix.\"\"\"\n",
    "    y, _ = librosa.load(audio_path, sr=SR, mono=True)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=SR, n_mfcc=N_MFCC)\n",
    "    return mfcc\n",
    "\n",
    "\n",
    "def run_mfcc_pipeline() -> None:\n",
    "    recordings_dir = next((p for p in RECORDINGS_DIR_CANDIDATES if p.exists()), None)\n",
    "    if recordings_dir is None:\n",
    "        raise FileNotFoundError(\n",
    "            \"Recordings directory not found. Checked: \"\n",
    "            + \", \".join(str(p) for p in RECORDINGS_DIR_CANDIDATES)\n",
    "        )\n",
    "\n",
    "    FEATURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    audio_files = sorted(\n",
    "        p\n",
    "        for p in recordings_dir.iterdir()\n",
    "        if p.suffix.lower() in {\".m4a\", \".wav\", \".mp3\"}\n",
    "    )\n",
    "    if not audio_files:\n",
    "        print(\"No audio files found in recordings directory.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Extracting MFCC features for {len(audio_files)} audio files...\")\n",
    "    for audio_path in audio_files:\n",
    "        try:\n",
    "            mfcc = extract_mfcc_features(audio_path)\n",
    "            feature_name = audio_path.name + \".npy\"\n",
    "            np.save(FEATURES_DIR / feature_name, mfcc)\n",
    "            print(f\"  ✓ {audio_path.name} -> {feature_name} ({mfcc.shape})\")\n",
    "        except Exception as exc:  # noqa: BLE001\n",
    "            print(f\"  ✗ Failed to process {audio_path.name}: {exc}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_mfcc_pipeline()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classical Model Training (`model.py`)\n",
    "\n",
    "Trains Random Forest, SVM, Naive Bayes, and an MLP on the averaged MFCC features stored in `features/`, then persists the resulting models as `.pkl` files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "ROOT_DIR = Path(__file__).resolve().parents[2]\n",
    "FEATURES_DIR = ROOT_DIR / \"features\"\n",
    "MODEL_FILES = {\n",
    "    \"rf.pkl\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"svm.pkl\": SVC(kernel=\"rbf\", C=1, gamma=\"scale\", random_state=42),\n",
    "    \"nb.pkl\": GaussianNB(),\n",
    "    \"ann.pkl\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42),\n",
    "}\n",
    "\n",
    "\n",
    "def load_and_average_data(file_patterns):\n",
    "    data_list = []\n",
    "    for file_name in sorted(file_patterns):\n",
    "        mfcc = np.load(FEATURES_DIR / file_name)\n",
    "        data_list.append(np.mean(mfcc, axis=1))\n",
    "    return np.vstack(data_list)\n",
    "\n",
    "\n",
    "def build_training_set():\n",
    "    autistic_files = [f for f in os.listdir(FEATURES_DIR) if f.startswith(\"aut_\")]\n",
    "    non_autistic_files = [f for f in os.listdir(FEATURES_DIR) if f.startswith(\"split-\")]\n",
    "    autistic_data = load_and_average_data(autistic_files)\n",
    "    non_autistic_data = load_and_average_data(non_autistic_files)\n",
    "\n",
    "    X = np.vstack((autistic_data, non_autistic_data))\n",
    "    y = np.hstack((np.ones(autistic_data.shape[0]), np.zeros(non_autistic_data.shape[0])))\n",
    "    return train_test_split(X, y, test_size=0.3, random_state=50)\n",
    "\n",
    "\n",
    "def train_models():\n",
    "    X_train, X_test, y_train, y_test = build_training_set()\n",
    "\n",
    "    for model_path, model in MODEL_FILES.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"{model.__class__.__name__} accuracy: {acc:.2f}\")\n",
    "        joblib.dump(model, ROOT_DIR / model_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_models()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Streamlit Inference UI (`ui.py`)\n",
    "\n",
    "Standalone application for uploading an audio file, extracting the averaged MFCC vector, and displaying the predicted label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import tempfile\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import librosa\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "ROOT_DIR = Path(__file__).resolve().parents[2]\n",
    "MODEL_INFO = {\n",
    "    \"rf.pkl\": \"Random Forest (~90% accuracy)\",\n",
    "    \"ann.pkl\": \"Artificial Neural Network (~72% accuracy)\",\n",
    "    \"svm.pkl\": \"Support Vector Machine (~54% accuracy)\",\n",
    "    \"nb.pkl\": \"Naive Bayes (~81% accuracy)\",\n",
    "}\n",
    "N_MFCC = 40\n",
    "\n",
    "\n",
    "def load_model(model_filename: str):\n",
    "    model_path = ROOT_DIR / model_filename\n",
    "    return joblib.load(model_path)\n",
    "\n",
    "\n",
    "def extract_features(file_bytes: bytes) -> np.ndarray:\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".m4a\") as tmp_file:\n",
    "        tmp_file.write(file_bytes)\n",
    "        tmp_path = tmp_file.name\n",
    "\n",
    "    try:\n",
    "        y, sr = librosa.load(tmp_path, sr=None, mono=True)\n",
    "        if y.size == 0:\n",
    "            raise ValueError(\"Empty audio signal\")\n",
    "\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=N_MFCC)\n",
    "        if np.isnan(mfcc).any():\n",
    "            raise ValueError(\"MFCC contains NaN values\")\n",
    "\n",
    "        mfcc_avg = np.mean(mfcc, axis=1)\n",
    "        return mfcc_avg.reshape(1, -1)\n",
    "    finally:\n",
    "        Path(tmp_path).unlink(missing_ok=True)\n",
    "\n",
    "\n",
    "st.title(\"Autism Detection\")\n",
    "\n",
    "selected_model_label = st.selectbox(\"Choose a model\", list(MODEL_INFO.values()))\n",
    "model_filename = next(key for key, value in MODEL_INFO.items() if value == selected_model_label)\n",
    "model = load_model(model_filename)\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Upload an audio file (m4a/wav/mp3)\", type=[\"m4a\", \"wav\", \"mp3\"])\n",
    "\n",
    "yes_style = '<h1 style=\"color:red;text-align:center;\">Prediction: Autistic</h1>'\n",
    "no_style = '<h1 style=\"color:green;text-align:center;\">Prediction: Non Autistic</h1>'\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    try:\n",
    "        features = extract_features(uploaded_file.getvalue())\n",
    "        prediction = model.predict(features)[0]\n",
    "        if prediction == 1:\n",
    "            st.markdown(yes_style, unsafe_allow_html=True)\n",
    "        else:\n",
    "            st.markdown(no_style, unsafe_allow_html=True)\n",
    "    except Exception as exc:  # noqa: BLE001\n",
    "        st.error(f\"Could not process audio file: {exc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Usage\n",
    "\n",
    "```bash\n",
    "# 1. Extract features\n",
    "python ../../mfcc_extract.py\n",
    "\n",
    "# 2. Train models (saves rf.pkl, svm.pkl, nb.pkl, ann.pkl)\n",
    "python ../../model.py\n",
    "\n",
    "# 3. Launch the Streamlit UI\n",
    "streamlit run ../../ui.py\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.13"
  },
  "kernelspec": {
   "name": "asd_adhd_detection",
   "display_name": "Python (ASD_ADHD_Detection)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}